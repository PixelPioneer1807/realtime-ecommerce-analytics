"""
Model 4: Hybrid Ensemble - Stacking Meta-Learner
Combines Random Forest + XGBoost + LightGBM predictions.

Expected Performance: 94-96% accuracy (BEST!)
Training Time: ~2 minutes
"""

import sys
from pathlib import Path
import time
import joblib
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import StackingClassifier
import warnings
warnings.filterwarnings('ignore')

# Add project root to path
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from ml_models.churn_prediction.utils.data_loader import DataLoader
from ml_models.churn_prediction.utils.evaluation import ModelEvaluator


def load_base_models():
    """Load all trained base models"""
    model_dir = Path(__file__).parent.parent / "trained_models"
    
    models = {}
    model_files = {
        'random_forest': 'random_forest_v1.pkl',
        'xgboost': 'xgboost_v1.pkl',
        'lightgbm': 'lightgbm_v1.pkl'
    }
    
    print("\nüì¶ Loading Base Models...")
    for name, filename in model_files.items():
        try:
            model_path = model_dir / filename
            models[name] = joblib.load(model_path)
            print(f"   ‚úì Loaded {name}")
        except Exception as e:
            print(f"   ‚úó Could not load {name}: {e}")
    
    return models


def train_hybrid_ensemble():
    """Train hybrid ensemble stacking classifier"""
    
    print("="*70)
    print("üèÜ MODEL 4: HYBRID ENSEMBLE (STACKING META-LEARNER)")
    print("="*70)
    
    # ========================================
    # STEP 1: Load data
    # ========================================
    print("\nüìÇ STEP 1: Loading Data...")
    loader = DataLoader()
    X_train, X_test, y_train, y_test, feature_names = loader.get_train_test_split()
    
    # ========================================
    # STEP 2: Load base models
    # ========================================
    print("\nüì¶ STEP 2: Loading Base Models...")
    base_models = load_base_models()
    
    if len(base_models) < 2:
        print("\n‚ùå Error: Need at least 2 base models!")
        print("   Please train Random Forest and XGBoost first.")
        print("\n   Run these commands:")
        print("   python ml-models/churn_prediction/models/01_random_forest.py")
        print("   python ml-models/churn_prediction/models/02_xgboost.py")
        return None, None
    
    print(f"\n   Successfully loaded {len(base_models)} base models ‚úÖ")
    
    # ========================================
    # STEP 3: Create stacking ensemble
    # ========================================
    print("\nüîÑ STEP 3: Creating Stacking Ensemble...")
    
    # Prepare estimators for stacking
    estimators = [(name, model) for name, model in base_models.items()]
    
    print(f"   Base models: {', '.join(base_models.keys())}")
    print(f"   Meta-learner: Logistic Regression")
    
    # Create stacking classifier
    stacking_clf = StackingClassifier(
        estimators=estimators,
        final_estimator=LogisticRegression(random_state=42, max_iter=1000),
        cv=5,  # 5-fold cross-validation
        stack_method='predict_proba',  # Use probabilities for stacking
        n_jobs=-1
    )
    
    # ========================================
    # STEP 4: Train ensemble
    # ========================================
    print("\nüéì STEP 4: Training Hybrid Ensemble...")
    print("   This may take 1-2 minutes...")
    
    start_time = time.time()
    
    # Fit stacking ensemble
    stacking_clf.fit(X_train, y_train)
    
    training_time = time.time() - start_time
    
    print(f"\n‚úÖ Ensemble trained in {training_time:.2f} seconds!")
    
    # ========================================
    # STEP 5: Evaluate ensemble
    # ========================================
    print("\nüìä STEP 5: Evaluating Hybrid Ensemble...")
    
    # Predictions
    y_pred = stacking_clf.predict(X_test)
    y_pred_proba = stacking_clf.predict_proba(X_test)[:, 1]
    
    # Evaluate
    evaluator = ModelEvaluator('hybrid_ensemble')
    results = evaluator.evaluate(y_test, y_pred, y_pred_proba)
    
    # ========================================
    # STEP 6: Individual model contributions
    # ========================================
    print("\n‚öñÔ∏è  STEP 6: Base Model Performance on Test Set:")
    
    print(f"\n   {'Model':<20} {'Accuracy':<12} {'Precision':<12} {'Recall':<12}")
    print(f"   {'-'*56}")
    
    for name, model in base_models.items():
        y_pred_base = model.predict(X_test)
        from sklearn.metrics import accuracy_score, precision_score, recall_score
        
        acc = accuracy_score(y_test, y_pred_base)
        prec = precision_score(y_test, y_pred_base)
        rec = recall_score(y_test, y_pred_base)
        
        print(f"   {name:<20} {acc:<12.4f} {prec:<12.4f} {rec:<12.4f}")
    
    print(f"   {'‚îÄ'*56}")
    print(f"   {'ENSEMBLE':<20} {results['accuracy']:<12.4f} {results['precision']:<12.4f} {results['recall']:<12.4f}")
    
    # ========================================
    # STEP 7: Meta-learner coefficients
    # ========================================
    print("\nüî¨ STEP 7: Meta-Learner Insights:")
    
    meta_model = stacking_clf.final_estimator_
    
    if hasattr(meta_model, 'coef_'):
        print(f"\n   Model Contribution Weights:")
        model_names = list(base_models.keys())
        weights = meta_model.coef_[0]
        
        for name, weight in zip(model_names, weights):
            direction = "‚Üë Positive" if weight > 0 else "‚Üì Negative"
            print(f"   {name:<20}: {weight:+.4f} {direction}")
        
        print(f"\n   Intercept: {meta_model.intercept_[0]:.4f}")
    
    # ========================================
    # STEP 8: Save ensemble
    # ========================================
    print("\nüíæ STEP 8: Saving Hybrid Ensemble...")
    
    model_dir = Path(__file__).parent.parent / "trained_models"
    model_path = model_dir / "hybrid_ensemble_v1.pkl"
    
    # Save complete ensemble
    joblib.dump(stacking_clf, model_path)
    print(f"   Ensemble saved to: {model_path}")
    
    # Prepare metadata
    additional_info = {
        'base_models': list(base_models.keys()),
        'n_base_models': len(base_models),
        'meta_learner': 'LogisticRegression',
        'stacking_method': 'predict_proba',
        'cv_folds': 5,
        'training_time_seconds': float(training_time),
        'model_weights': dict(zip(model_names, weights.tolist())) if hasattr(meta_model, 'coef_') else None
    }
    
    evaluator.save_results(additional_info)
    evaluator.plot_confusion_matrix(y_test, y_pred)
    
    # ========================================
    # STEP 9: Final comparison
    # ========================================
    print("\nüìä STEP 9: Complete Model Comparison...")
    
    try:
        import json
        results_dir = Path(__file__).parent.parent / "results"
        
        print(f"\n   {'Model':<20} {'Accuracy':<12} {'Precision':<12} {'Recall':<12} {'F1':<12}")
        print(f"   {'-'*68}")
        
        all_models = ['random_forest', 'xgboost', 'lightgbm', 'hybrid_ensemble']
        best_accuracy = 0
        best_model = ""
        
        for model_name in all_models:
            result_file = results_dir / f"{model_name}_results.json"
            if result_file.exists():
                with open(result_file, 'r') as f:
                    model_results = json.load(f)
                
                acc = model_results['accuracy']
                if acc > best_accuracy:
                    best_accuracy = acc
                    best_model = model_name
                
                marker = "üèÜ" if model_name == best_model or model_name == 'hybrid_ensemble' else "  "
                
                print(f"{marker} {model_name:<20} "
                      f"{model_results['accuracy']:<12.4f} "
                      f"{model_results['precision']:<12.4f} "
                      f"{model_results['recall']:<12.4f} "
                      f"{model_results['f1_score']:<12.4f}")
    except Exception as e:
        print(f"   Could not load previous results: {e}")
    
    # ========================================
    # STEP 10: Final summary
    # ========================================
    print("\n" + "="*70)
    print("üéâ HYBRID ENSEMBLE TRAINING COMPLETE!")
    print("="*70)
    print(f"\nüìà Final Metrics:")
    print(f"   Accuracy:  {results['accuracy']*100:.2f}%")
    print(f"   Precision: {results['precision']:.4f}")
    print(f"   Recall:    {results['recall']:.4f}")
    print(f"   F1-Score:  {results['f1_score']:.4f}")
    print(f"   ROC-AUC:   {results['roc_auc']:.4f}")
    
    print(f"\nüèÜ Ensemble Strategy:")
    print(f"   ‚úì Base Models: {len(base_models)} ({', '.join(base_models.keys())})")
    print(f"   ‚úì Meta-Learner: Logistic Regression")
    print(f"   ‚úì Stacking Method: Probability-based")
    print(f"   ‚úì Cross-Validation: 5-fold")
    print(f"   ‚úì Training Time: {training_time:.2f} seconds")
    
    print(f"\nüíæ Outputs:")
    print(f"   Model: {model_path}")
    print(f"   Results: ml-models/churn_prediction/results/hybrid_ensemble_results.json")
    print(f"   Confusion Matrix: ml-models/churn_prediction/results/hybrid_ensemble_confusion_matrix.png")
    
    print("\n‚úÖ ALL MODELS COMPLETE! üéâüéâüéâ")
    print("\nüìä Next Steps:")
    print("   1. Review results.md comparison")
    print("   2. Deploy best model to production")
    print("   3. Integrate with real-time stream aggregator")
    
    print("="*70 + "\n")
    
    return stacking_clf, results


if __name__ == "__main__":
    model, results = train_hybrid_ensemble()
